---
title: "Preparing trait databases"
author: "Quang Nguyen"
date: "2022-03-12"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

## Introduction

We're prepping the latest database for export for evaluation. For this manuscript, we're merging a couple of existing databases:  

1. The comprehensive synthesis of trait-database from [Madin et al. 2020](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7275036/). This database was last updated in 2020. Most of the database's sources are static sources, with the exception of the [GOLD database](https://gold.jgi.doe.gov/downloads). As such, we're merging the existing release of the Madin et al. database with the most recent GOLD release (2022-03-12).  
2. Manual curation of bergey's manual by [Weissman et al.](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04216-2). This database contains manual curation of the Bergey's manual specific to human-associated microbiomes.   

The way we're trying to combine these disparate sources would be to perform something similar to Madin et al. using the [R code](https://github.com/bacteria-archaea-traits/bacteria-archaea-traits/blob/master/R/functions.R) on GitHub. The step-by-step workflow is:  

1. Prepare and process each individual database file.  
2. Second, concatenate all database files by row. Remember to specify data source. 
3. 

## Analysis  

Loading some packages

```{r}
library(piggyback)
library(data.table)
library(dtplyr)
library(targets)
library(here)
library(tidyverse)
here::i_am("analysis/db_prep.Rmd")
```


### Downloading data files  

Downloading data files from respective sources and version control on GitHub using `piggyback`  

```{r, eval=FALSE}
# Not run since file is large and is already uploaded to GitHub. Code here for provenance 
piggyback::pb_upload(file = here("large_files", "goldData.xlsx"), tag = "0.1", overwrite = TRUE)

```

### Processing data files  

First, load the original Madin et al. database  
```{r}
base <- read_csv(here("data", "condensed_species_NCBI.txt"))
```


Let's process GOLD. First, load data from `piggyback` (this is cached). Script follows existing processing pipeline [here](https://github.com/bacteria-archaea-traits/bacteria-archaea-traits/blob/master/R/preparation/gold.R) from Madin et al.   

```{r, cache=TRUE}
pth <- here("large_files")
if (!file.exists(pth)){
    piggyback::pb_download(file = "goldData.xlsx", dest = pth, tag = "0.1")
}
gold <- readxl::read_xlsx(path = file.path(pth, "goldData.xlsx"), sheet = "Organism")
```


```{r}
# convert names 
colnames(gold) <- colnames(gold) %>% 
    gsub(x = ., pattern = " ", replacement = "_") %>% 
    tolower() %>% 
    gsub(x = ., pattern = "organism_", replacement = "")



gold %>% 
    select(name, ncbi_tax_id, ncbi_superkingdom,  
            ncbi_phylum, ncbi_order, ncbi_family, ncbi_genus, ncbi_species, 
            gram_stain, metabolism, energy_sources, oxygen_requirement, 
            sporulation, motility, cell_shape) %>% 
    # rename("species_tax_id" = ncbi_tax_id, 
    #        "superkingdom" = ncbi_superkingdom,
    #        "phylum" = ncbi_phylum, 
    #        "order" = ncbi_order, 
    #        "family" = ncbi_family, 
    #        "genus" = ncbi_genus, 
    #        "species" = ncbi_species, 
    #        "pathways" = , 
    #        "metabolism" = oxygen_requirement)
    





```






