---
title: "Preparing trait databases"
author: "Quang Nguyen"
date: "2022-03-12"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", autodep = TRUE)
```

# Introduction

We're prepping the latest database for export for evaluation. For this manuscript, we're merging a couple of existing databases:  

1. The comprehensive synthesis of trait-database from [Madin et al. 2020](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7275036/). This database was last updated in 2020. Most of the database's sources are static sources, with the exception of the [GOLD database](https://gold.jgi.doe.gov/downloads). As such, we're merging the existing release of the Madin et al. database with the most recent GOLD release (2022-03-12).  
2. Manual curation of bergey's manual by [Weissman et al.](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04216-2). This database contains manual curation of the Bergey's manual specific to human-associated microbiomes.   

The way we're trying to combine these disparate sources would be to perform something similar to Madin et al. using the [R code](https://github.com/bacteria-archaea-traits/bacteria-archaea-traits/blob/master/R/functions.R) on GitHub. We're going to apply relevant transformations and mappings where apply.  

# Analysis  

Loading some packages

```{r}
library(piggyback)
library(data.table)
library(dtplyr)
library(targets)
library(here)
library(stringdist)
library(tidyverse)
here::i_am("analysis/db_prep.Rmd")
```


## Downloading data files  

Downloading data files from respective sources and version control on GitHub using `piggyback`  

```{r, eval=FALSE}
# Not run since file is large and is already uploaded to GitHub. Code here for provenance 
piggyback::pb_upload(file = here("large_files", "goldData.xlsx"), tag = "0.1", overwrite = TRUE)

```

## Processing data files 

First, load the original Madin et al. database  
```{r}
base <- read_csv(here("data", "condensed_species_NCBI.txt")) %>% 
    select(species_tax_id, superkingdom, phylum, class, order, family, 
           genus, species, metabolism, gram_stain, pathways, 
           carbon_substrates, sporulation, motility, cell_shape) %>% 
    rename("substrate" = carbon_substrates)
```

### Processing GOLD  

Let's process GOLD. First, load data from `piggyback` (this is cached). Script follows existing processing pipeline [here](https://github.com/bacteria-archaea-traits/bacteria-archaea-traits/blob/master/R/preparation/gold.R) from Madin et al.   

```{r, warning=FALSE}
pth <- here("large_files", "goldData.csv")
if (!file.exists(pth)){
    piggyback::pb_download(file = "goldData.xlsx", dest = here("large_files"), tag = "0.1")
    gold <- readxl::read_xlsx(path = here("large_files", "goldData.xlsx"), sheet = "Organism")
    readr::write_csv(x = gold, file = pth)
}
gold <- read_csv(file = pth)
```

Let's perform name conversions  

```{r, cache = TRUE}
# convert names 
colnames(gold) <- colnames(gold) %>% 
    gsub(x = ., pattern = " ", replacement = "_") %>% 
    tolower() %>% 
    gsub(x = ., pattern = "organism_", replacement = "")


gold_reduced <- gold %>% 
    select(ncbi_tax_id, ncbi_superkingdom,  
            ncbi_phylum, ncbi_order, ncbi_family, ncbi_genus, ncbi_species, 
            name, gram_stain, metabolism, oxygen_requirement, 
            sporulation, motility, cell_shape) %>% 
    rename("species_tax_id" = ncbi_tax_id,
           "superkingdom" = ncbi_superkingdom,
           "phylum" = ncbi_phylum,
           "order" = ncbi_order,
           "family" = ncbi_family,
           "genus" = ncbi_genus,
           "species" = ncbi_species,
           "pathways" = metabolism,
           "metabolism" = oxygen_requirement) %>% as.data.table()

# nest traits 
tbl <- gold_reduced %>%
    select(-name) %>%
    group_by(species_tax_id, superkingdom, phylum, order, 
             family, genus, species) %>%
    nest(traits = c(gram_stain, pathways, metabolism, 
           cell_shape, motility, sporulation))
    

# a subset of the table that has more than one row per trait nested values 
tbl_munge <- tbl %>% filter(map_lgl(traits, ~{nrow(.x) > 1}))
```

The issue is that there some species with multiple entries per species due to differences in certain characteristics but also multiple strains per species. Here, we're going to loop over all of those rows and then replace them. Since the original database is at species level, we're also going to collapse from the strain level to the species level similar to Madin et al. 2020 

Let's define a function that processes species that have multiple entries in GOLD 

```{r}
# This function takes a data frame and a column 
# and selects the response with the highest frequency
select_best <- function(df, column){
    vec <- unlist(df[,..column])
    freq <- as.data.frame(table(vec))
    if (nrow(freq) == 0){
        return(NA)
    } else {
        return(freq %>% filter(Freq == max(Freq)) %>% 
                   pull(vec) %>% as.character())
    }
}

# This function then utilizes select_best
# to process entries with duplicates (more than one row)
# for pathways, the goal is to concatenate them
process_duplicates <- function(df){
    # get only unique rows
    df <- unique(df)
    if (nrow(df) == 1){
        return(df)
    }
    v <- c("gram_stain", "pathways", "metabolism", 
           "sporulation", "motility", "cell_shape")
    suppressMessages(res <- map_dfc(v, ~{
        if (.x == "pathways"){
            str_vec <- na.omit(df$pathways)
            if (length(str_vec) == 0){
                out <- NA
            } else {
                out <- str_replace(str_vec, pattern = " ", 
                                   replacement = "_") %>% 
                    paste(collapse = ", ")
            }
        } else {
            out <- select_best(df, .x)
        }
        return(out)
    }))
    colnames(res) <- v
    res <- as.data.table(res)
    return(res)
}
```

Let's apply it to `tbl_munge` and then merge both data frames together into one consensus trait. After this munging, the final GOLD database is processed and ready to merge into the master `base` data frame  

```{r, cache = TRUE}

tbl_munge <- tbl_munge %>% 
    mutate(traits = map(traits, process_duplicates)) %>% as_tibble() %>% 
    unnest(traits)

```

We merge by extracting the `species_tax_id` column out of `tbl`, remove all rows with that identifier and then replace that with those from the `tbl_munge` database. 

```{r}

ids <- tbl_munge %>% pull(species_tax_id)

gold_final <- tbl %>% filter(!species_tax_id %in% ids) %>% 
    as_tibble() %>% 
    unnest(traits) %>% bind_rows(tbl_munge)

head(gold_final)
```

`gold_final` will now be the finalized form of the GOLD database as put into the original format of Madin et al.  

### Processing Weissman et al.  

```{r}

weissman <- read_csv(here("data", "weissman.csv"))

# select the relevant columns
weissman <- weissman %>% select(c("taxid_species",
                                  "kingdom", "phylum", "class", "order", "family", "genus", "species",
                                  "Motility_general", "Oxygen.Preference", "Cell.Shape", "Cell.Aggregation",
                                  starts_with("Enzyme.Assays"), 
                                  starts_with("Volatile.Gas.Production"), 
                                  starts_with("Substrate.Utilization")))

```

Here, we're going to re-format it similar to Madin et al. `Enzyme.Assays` and `Volatile.Gas.Production` is equivalent to `pathways` while `Substrate.Utililization` is equivalent to `carbon_substrates`. Since there might be non-carbon compounds here, we're going to rename Madin et al.'s `carbon_substrates` into just `substrate` here similar to Weissman's database.  

```{r}
weissman <- weissman %>% group_by(taxid_species, kingdom, phylum, 
                      class, order, family, genus, species) %>%
    nest(pathways = starts_with(c("Enzyme.Assays", "Volatile.Gas.Production")), 
         substrate = starts_with("Substrate.Utilization")) %>% ungroup() %>% 
    mutate(across(where(is.character), ~na_if(., "0"))) %>% 
    rename("species_tax_id" = taxid_species, "superkingdom" = kingdom, 
           "metabolism" = Oxygen.Preference,
           "motility" = Motility_general, "cell_shape" = Cell.Shape, "cell_aggregation" = Cell.Aggregation)
```

Here we're going to define some functions to process the traits that is internal (collapse into one column) for pathways and for substrates  

```{r}
#' @param unit A single unit from a list of trait data frames
proc_pathways <- function(unit){
    string <- unit %>% pivot_longer(everything()) %>% 
        filter(value != 0)
    if (nrow(string) == 0){
        return(NA)
    } else {
        string <- string %>% 
            mutate(name = str_replace(name, pattern = "Enzyme.Assays..", replacement = "")) %>%
            mutate(name = str_replace(name, pattern = "Volatile.Gas.Production..", replacement = "synthesis_")) %>%
            mutate(name = str_replace(name, pattern = "\\.$", "")) %>%
            mutate(name = str_replace(name, pattern = "\\.\\.(.*)$", "")) %>%
            mutate(name = str_replace_all(name, pattern = "\\.", "_")) %>% 
            rowwise() %>%
            mutate(name = if_else(str_detect(name, "synthesis_"), 
                                  true = paste(rev(str_split(name, pattern = "_", 
                                                             n = 2)[[1]]), 
                                               collapse = "_"),
                                  false = name)) %>% 
            ungroup() %>%
            pull(name) %>% paste(., collapse = ", ")
    }
        
    return(string)
}

proc_substrate <- function(unit){
    string <- unit %>% pivot_longer(everything()) %>% filter(value != 0)
    if (nrow(string) == 0){
        return(NA)
    } else {
        string <- string %>% mutate(name = str_split(name, pattern = "\\.\\.", 
                                           n = 2, simplify = TRUE)[,2]) %>%
            mutate(name = str_replace(name, "(\\.\\.|\\.)$", "")) %>% 
            mutate(name = str_replace_all(name, "(\\.\\.|\\.)", "_")) %>% 
            pull(name) %>% paste(., collapse = ", ")
    }
    return(string)
}

```


Map it over the two columns in the original data frame.   

```{r, cache=TRUE}
substr <- map_chr(weissman$substrate, proc_substrate)
pthway <- map_chr(weissman$pathways, proc_pathways)

weissman <- weissman %>% select(-c(pathways, substrate)) %>% 
  mutate(substrate = substr, pathways = pthway)
```


### Combining the databases 

First, we define a function to check for similar sounding names across all the unique pathways and substrates for all the data sets. Here, we use the `stringdist` function from the `stringdist` package. We use the standard OSA metric (also called the Damerau-Levenshtein distance) to query for potential similarly sounding names of identical pathways or compounds.   

```{r}

check_matches <- function(df, type=c("pathways","substrates")){
    b_val <- base %>% pull(!!type) %>% unique() %>% str_split(pattern = ", ") %>%
        unlist() %>% unique() %>% na.omit() %>% as.vector()
    
    q_val <- df %>% pull(!!type) %>% unique() %>% str_split(pattern = ", ") %>% 
        unlist() %>% unique() %>% na.omit() %>% as.vector()
    
    check <- map(q_val, ~{
        match <- stringdist(a = .x, b = b_val)
        # match 0 is the same, and match > 2 is too different 
        ret <- b_val[match > 0 & match <= 2]
        if (length(ret) == 0){
            return(NA)
        } else {
            out <- tibble(
                query = rep(.x, length(ret)),
                ref = ret
            )
        }
    })
    check <- check[!sapply(check, function(x) all(is.na(x)))]
    
    return(check)
}

```


Check Weissman et al. database  

```{r}
check_matches(weissman, "pathways")
check_matches(weissman, "substrate")

```

We can see that for a lot of the compounds the names might be the same but they're actually different. However, there are certain conventions such as "_" for spaces or "-" that we might need to address for the final merge.  

Let's check the GOLD database for similar sounding names  












